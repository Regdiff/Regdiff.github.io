# 卷积神经网络

##  DenseNet

1. `DenseNet`不是通过更深或者更宽的结构，而是通过特征重用来提升网络的学习能力。

2. `ResNet` 的思想是：创建从“靠近输入的层” 到 “靠近输出的层” 的直连。而`DenseNet` 做得更为彻底：将所有层以前馈的形式相连，这种网络因此称作`DenseNet` 。

3. `DenseNet` 具有以下的优点：

   - 缓解梯度消失的问题。因为每层都可以直接从损失函数中获取梯度、从原始输入中获取信息，从而易于训练。
   - 密集连接还具有正则化的效应，缓解了小训练集任务的过拟合。
   - 鼓励特征重用。网络将不同层学到的 `feature map` 进行组合。
   - 大幅度减少参数数量。因为每层的卷积核尺寸都比较小，输出通道数较少 (由增长率  决定)。

4. `DenseNet` 具有比传统卷积网络更少的参数，因为它不需要重新学习多余的`feature map` 。

   - 传统的前馈神经网络可以视作在层与层之间传递`状态`的算法，每一层接收前一层的`状态`，然后将新的`状态`传递给下一层。

     这会改变`状态`，但是也传递了需要保留的信息。

   - `ResNet` 通过恒等映射来直接传递需要保留的信息，因此层之间只需要传递`状态的变化` 。

   - `DenseNet` 会将所有层的`状态` 全部保存到`集体知识`中，同时每一层增加很少数量的`feture map` 到网络的`集体知识中`。

5. `DenseNet` 的层很窄（即：`feature map` 的通道数很小），如：每一层的输出只有 12 个通道。